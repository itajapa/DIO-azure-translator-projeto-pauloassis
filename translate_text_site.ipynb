{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBnwFYXVskzA",
        "outputId": "244a6821-23e5-48c2-bc2a-7d18ca671e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.2.8)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.8)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-1.1.7\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 openai langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "      for script_or_style in soup(['script', 'style']):\n",
        "        script_or_style.decompose()\n",
        "      texto = soup.get_text(separator= ' ')\n",
        "      #limpar texto\n",
        "      lines = (line.strip() for line in texto.splitlines())\n",
        "      parts = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "      texto_limpo = '\\n'.join(part for part in parts if part)\n",
        "      return texto_limpo\n",
        "    else:\n",
        "        print(f\"Failed to fetch the URL. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    text = soup.get_text()\n",
        "    return text\n",
        "\n",
        "extract_text_from_url('ADD_WEBSITE_LINK_HERE')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "vxQxC-5Cs-OE",
        "outputId": "1a7d0ee2-e82c-475b-fd46-7e2a4dfec0fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Azure Open AI in VNet - DEV Community\\nSkip to content\\nNavigation menu\\nSearch\\nPowered by Algolia\\nSearch\\nLog in\\nCreate account\\nDEV Community\\nClose\\nAdd reaction\\nLike\\nUnicorn\\nExploding Head\\nRaised Hands\\nFire\\nJump to Comments\\nSave\\nBoost\\nMore...\\nCopy link\\nCopy link\\nCopied to Clipboard\\nShare to X\\nShare to LinkedIn\\nShare to Facebook\\nShare to Mastodon\\nReport Abuse\\nKenichiro Nakamura\\nPosted on\\nOct 12, 2023\\nAzure Open AI in VNet\\n# azure\\n# openai\\n# security\\nGPT models are hosted in multiple service vendor at the moment, and Microsoft Azure is one of them.\\nEven though the models themselves are the same, there are many differences including:\\ncost\\nfunctionalities\\ntype of models and versions\\ngeo location\\nsecurity\\nsupport\\netc.\\nOne of the most important aspects when we use it in an Enterprise Environment is, of course, security.\\nBy using Azure network security features with Azure Open AI, customers can consume the Open AI service from and within the VNet, therefore no information is flowing in public.\\nSample Deployment\\nAzure Sample repo provides a sample bicep files to deploy Azure Open AI into VNet environment.\\nGitHub: openai-enterprise-iac\\nThe key features the bicep uses are:\\nVNet\\nVNet integration for Web App\\nPrivate Endpoint for Azure Open AI\\nPrivate Endpoint for Cognitive Search\\nPrivate DNS Zone\\nBy using these features, all the outbound traffic from the Web App only routed inside the VNet and all the names are resolved into private IP addresses. Open AI and Cognitive Search shut down the public IP address, thus there is not public interface endpoint available anymore.\\nDeploy\\nThe bicep file will deploy following Azure Resources.\\nLet's deploy and confirm how it works. I create a resource group in East US region for my own test.\\ngit clone https://github.com/Azure-Samples/openai-enterprise-iac\\ncd\\nopenai-enterprise-iac\\naz group create\\n-n\\nopenaitest\\n-l\\neastus\\naz deployment group create\\n-g\\nopenaitest\\n-f\\n. \\\\i nfra \\\\m ain.bicep\\nEnter fullscreen mode\\nExit fullscreen mode\\nOnce I run the commend above, I see the deployment started.\\nWait until the deployment completes.\\nTest\\nLet's see if the deployment was succeeded.\\nAzure Open AI\\nLet's try public access first.\\nI could create a deployment without any issue. But when I try from the Chat playground in my Azure Portal, I see the following error.\\nHow about access via the Web API?\\nFrom an advanced tool of the App Service, I login to Bash session, and first I ping the service URL.\\nI see the private IP address assigned to the Private Endpoint is returend.\\nThen I use curl command to send request to the endpoint.\\nTop comments\\n(0)\\nSubscribe\\nPersonal\\nTrusted User\\nCreate template\\nTemplates let you quickly answer FAQs or store snippets for re-use.\\nSubmit\\nPreview\\nDismiss\\nCode of Conduct\\n‚Ä¢\\nReport abuse\\nAre you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's\\npermalink .\\nHide child comments as well\\nConfirm\\nFor further actions, you may consider blocking this person and/or\\nreporting abuse\\nKenichiro Nakamura\\nFollow\\nJoined\\nFeb 3, 2018\\nMore from\\nKenichiro Nakamura\\nAzure ML Prompt flow: Use content safety before sending a request to LLM\\n# azure\\n# promptflow\\n# contentsafety\\nDon't waste time to write README, use readme-ai instead\\n# ai\\n# readme\\n# openai\\nC#: Azure Open AI and Function Calling\\n# azure\\n# openai\\n# functioncalling\\nüíé DEV Diamond Sponsors\\nThank you to our Diamond Sponsors for supporting the DEV Community\\nGoogle AI is the official AI Model and Platform Partner of DEV\\nNeon is the official database partner of DEV\\nAlgolia is the official search partner of DEV\\nDEV Community\\n‚Äî Discussing the core forem open source software project ‚Äî features, bugs, performance, self-hosting.\\nHome\\nReading List\\nAbout\\nContact\\nCode of Conduct\\nPrivacy Policy\\nTerms of Use\\nBuilt on\\nForem\\n‚Äî the\\nopen source\\nsoftware that powers\\nDEV\\nand other inclusive communities.\\nMade with love and\\nRuby on Rails . DEV Community\\n¬©\\n2016 - 2026.\\nCommunity building community\\nLog in\\nCreate account\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
        "\n",
        "client = AzureChatOpenAI (\n",
        "    azure_endpoint= \"YOUR_ENDPOINT_HERE\",\n",
        "    api_key= \"YOUR_KEY_HERE\",\n",
        "    api_version= \"2024-02-15-preview\",\n",
        "    deployment_name= \"YOUR_DEPLOYMENT_NAME\",\n",
        "    max_retries=0\n",
        ")\n",
        "\n",
        "def translate_article(text, lang):\n",
        "  messages = [\n",
        "      (\"system\", \"Voc√™ atua como tradutor de textos\"),\n",
        "      (\"user\", f\"Traduza o {text} para o idioma {lang} e responda em markdown\")\n",
        "  ]\n",
        "\n",
        "  response = client.invoke(messages)\n",
        "  print(response.content)\n",
        "  return response.content\n",
        "\n",
        "translate_article(\"I love you\", \"portugues\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "vUKnnDoJxd7Y",
        "outputId": "46418125-f1c7-455d-fb4a-9eeedc17557f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```markdown\n",
            "Eu te amo\n",
            "```\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```markdown\\nEu te amo\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'ADD_WEBSITE_LINK_HERE'\n",
        "text = extract_text_from_url(url)\n",
        "article = translate_article(text, \"pt-br\")\n",
        "\n",
        "print(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0IFuIBH8B9g",
        "outputId": "41a371bd-f9ef-4b1a-cddd-333fcf817c9d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Azure Open AI na VNet\n",
            "\n",
            "## Navega√ß√£o\n",
            "- Pesquisar\n",
            "- Fazer login\n",
            "- Criar conta\n",
            "- DEV Community\n",
            "\n",
            "Kenichiro Nakamura  \n",
            "Publicado em 12 de outubro de 2023\n",
            "\n",
            "---\n",
            "\n",
            "Os modelos GPT est√£o atualmente hospedados em v√°rios fornecedores de servi√ßos, e o Microsoft Azure √© um deles. Embora os pr√≥prios modelos sejam os mesmos, existem muitas diferen√ßas, incluindo:\n",
            "- custo\n",
            "- funcionalidades\n",
            "- tipos de modelos e vers√µes\n",
            "- localiza√ß√£o geogr√°fica\n",
            "- seguran√ßa\n",
            "- suporte\n",
            "- etc.\n",
            "\n",
            "Um dos aspectos mais importantes ao utiliz√°-lo em um ambiente corporativo √©, claro, a seguran√ßa. \n",
            "\n",
            "Ao usar os recursos de seguran√ßa de rede do Azure com o Azure Open AI, os clientes podem consumir o servi√ßo Open AI a partir e dentro da VNet, portanto, nenhuma informa√ß√£o est√° fluindo publicamente.\n",
            "\n",
            "## Exemplo de Implanta√ß√£o\n",
            "O reposit√≥rio de amostras do Azure fornece arquivos de Bicep de exemplo para implantar o Azure Open AI em um ambiente VNet.  \n",
            "GitHub: [openai-enterprise-iac](https://github.com/Azure-Samples/openai-enterprise-iac)\n",
            "\n",
            "As principais caracter√≠sticas que o Bicep utiliza s√£o:\n",
            "- VNet\n",
            "- Integra√ß√£o do VNet para App Web\n",
            "- Endpoint Privado para Azure Open AI\n",
            "- Endpoint Privado para Busca Cognitiva\n",
            "- Zona DNS Privada\n",
            "\n",
            "Ao usar esses recursos, todo o tr√°fego de sa√≠da do App Web √© roteado apenas dentro da VNet e todos os nomes s√£o resolvidos em endere√ßos IP privados. O Open AI e a Busca Cognitiva desabilitam o endere√ßo IP p√∫blico, portanto, n√£o h√° mais um endpoint de interface p√∫blica dispon√≠vel.\n",
            "\n",
            "## Implantar\n",
            "O arquivo Bicep implantar√° os seguintes recursos do Azure. Vamos implantar e confirmar como isso funciona. Crio um grupo de recursos na regi√£o East US para meu pr√≥prio teste.\n",
            "\n",
            "```bash\n",
            "git clone https://github.com/Azure-Samples/openai-enterprise-iac\n",
            "cd openai-enterprise-iac\n",
            "az group create -n openaitest -l eastus\n",
            "az deployment group create -g openaitest -f ./infra/main.bicep\n",
            "```\n",
            "\n",
            "Assim que eu executar o comando acima, vejo que a implanta√ß√£o foi iniciada.  \n",
            "Aguarde at√© que a implanta√ß√£o seja conclu√≠da.\n",
            "\n",
            "## Teste\n",
            "Vamos ver se a implanta√ß√£o foi bem-sucedida. \n",
            "\n",
            "### Azure Open AI\n",
            "Vamos tentar o acesso p√∫blico primeiro.  \n",
            "Consegui criar uma implanta√ß√£o sem problemas. Mas, ao tentar do playground de Chat no meu Portal Azure, vejo o seguinte erro.  \n",
            "E quanto ao acesso via API Web?  \n",
            "De uma ferramenta avan√ßada do App Service, fa√ßo login na sess√£o Bash e primeiro fa√ßo um ping na URL do servi√ßo.  \n",
            "Vejo que o endere√ßo IP privado atribu√≠do ao Endpoint Privado est√° sendo retornado.  \n",
            "Ent√£o, uso o comando `curl` para enviar uma solicita√ß√£o ao endpoint.\n",
            "\n",
            "---\n",
            "\n",
            "Para mais intera√ß√µes e contribui√ß√µes, sinta-se √† vontade para seguir Kenichiro Nakamura e participar das discuss√µes sobre Azure e Open AI na DEV Community.\n",
            "# Azure Open AI na VNet\n",
            "\n",
            "## Navega√ß√£o\n",
            "- Pesquisar\n",
            "- Fazer login\n",
            "- Criar conta\n",
            "- DEV Community\n",
            "\n",
            "Kenichiro Nakamura  \n",
            "Publicado em 12 de outubro de 2023\n",
            "\n",
            "---\n",
            "\n",
            "Os modelos GPT est√£o atualmente hospedados em v√°rios fornecedores de servi√ßos, e o Microsoft Azure √© um deles. Embora os pr√≥prios modelos sejam os mesmos, existem muitas diferen√ßas, incluindo:\n",
            "- custo\n",
            "- funcionalidades\n",
            "- tipos de modelos e vers√µes\n",
            "- localiza√ß√£o geogr√°fica\n",
            "- seguran√ßa\n",
            "- suporte\n",
            "- etc.\n",
            "\n",
            "Um dos aspectos mais importantes ao utiliz√°-lo em um ambiente corporativo √©, claro, a seguran√ßa. \n",
            "\n",
            "Ao usar os recursos de seguran√ßa de rede do Azure com o Azure Open AI, os clientes podem consumir o servi√ßo Open AI a partir e dentro da VNet, portanto, nenhuma informa√ß√£o est√° fluindo publicamente.\n",
            "\n",
            "## Exemplo de Implanta√ß√£o\n",
            "O reposit√≥rio de amostras do Azure fornece arquivos de Bicep de exemplo para implantar o Azure Open AI em um ambiente VNet.  \n",
            "GitHub: [openai-enterprise-iac](https://github.com/Azure-Samples/openai-enterprise-iac)\n",
            "\n",
            "As principais caracter√≠sticas que o Bicep utiliza s√£o:\n",
            "- VNet\n",
            "- Integra√ß√£o do VNet para App Web\n",
            "- Endpoint Privado para Azure Open AI\n",
            "- Endpoint Privado para Busca Cognitiva\n",
            "- Zona DNS Privada\n",
            "\n",
            "Ao usar esses recursos, todo o tr√°fego de sa√≠da do App Web √© roteado apenas dentro da VNet e todos os nomes s√£o resolvidos em endere√ßos IP privados. O Open AI e a Busca Cognitiva desabilitam o endere√ßo IP p√∫blico, portanto, n√£o h√° mais um endpoint de interface p√∫blica dispon√≠vel.\n",
            "\n",
            "## Implantar\n",
            "O arquivo Bicep implantar√° os seguintes recursos do Azure. Vamos implantar e confirmar como isso funciona. Crio um grupo de recursos na regi√£o East US para meu pr√≥prio teste.\n",
            "\n",
            "```bash\n",
            "git clone https://github.com/Azure-Samples/openai-enterprise-iac\n",
            "cd openai-enterprise-iac\n",
            "az group create -n openaitest -l eastus\n",
            "az deployment group create -g openaitest -f ./infra/main.bicep\n",
            "```\n",
            "\n",
            "Assim que eu executar o comando acima, vejo que a implanta√ß√£o foi iniciada.  \n",
            "Aguarde at√© que a implanta√ß√£o seja conclu√≠da.\n",
            "\n",
            "## Teste\n",
            "Vamos ver se a implanta√ß√£o foi bem-sucedida. \n",
            "\n",
            "### Azure Open AI\n",
            "Vamos tentar o acesso p√∫blico primeiro.  \n",
            "Consegui criar uma implanta√ß√£o sem problemas. Mas, ao tentar do playground de Chat no meu Portal Azure, vejo o seguinte erro.  \n",
            "E quanto ao acesso via API Web?  \n",
            "De uma ferramenta avan√ßada do App Service, fa√ßo login na sess√£o Bash e primeiro fa√ßo um ping na URL do servi√ßo.  \n",
            "Vejo que o endere√ßo IP privado atribu√≠do ao Endpoint Privado est√° sendo retornado.  \n",
            "Ent√£o, uso o comando `curl` para enviar uma solicita√ß√£o ao endpoint.\n",
            "\n",
            "---\n",
            "\n",
            "Para mais intera√ß√µes e contribui√ß√µes, sinta-se √† vontade para seguir Kenichiro Nakamura e participar das discuss√µes sobre Azure e Open AI na DEV Community.\n"
          ]
        }
      ]
    }
  ]
}